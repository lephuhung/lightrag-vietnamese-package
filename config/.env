### LightRAG Server Configuration for Local LLM + Vietnamese Setup
### 
### Model: glm-4-9b via Local OpenAI-compatible API
### Embedding: OpenAI Compatible (cần cấu hình thêm - xem hướng dẫn bên dưới)

###########################
### Server Configuration
###########################
HOST=0.0.0.0
PORT=9621
WEBUI_TITLE='LightRAG Vietnamese'
WEBUI_DESCRIPTION="LightRAG Server với Local LLM và Vietnamese Embedding"

### Worker configuration
WORKERS=2
TIMEOUT=300

### Directory Configuration
INPUT_DIR=./inputs
WORKING_DIR=./rag_storage

### Logging level
LOG_LEVEL=INFO
VERBOSE=False

#####################################
### Query Configuration
#####################################
ENABLE_LLM_CACHE=true
SUMMARY_LANGUAGE=Vietnamese

### Context control
TOP_K=40
CHUNK_TOP_K=20
MAX_ENTITY_TOKENS=6000
MAX_RELATION_TOKENS=8000
MAX_TOTAL_TOKENS=30000

#####################################
### Document Processing
#####################################
ENABLE_LLM_CACHE_FOR_EXTRACT=true

### Chunk configuration
CHUNK_SIZE=1200
CHUNK_OVERLAP_SIZE=100

### Entity types for Vietnamese
ENTITY_TYPES='["Ngườii", "Tổ chức", "Địa điểm", "Sự kiện", "Sản phẩm", "Công nghệ", "Khái niệm"]'

### Concurrency
MAX_ASYNC=4
MAX_PARALLEL_INSERT=2

########################################
### Reranking configuration
########################################
RERANK_BINDING=null

###########################################################################
### LLM Configuration - Local OpenAI Compatible API
###########################################################################
LLM_BINDING=openai
LLM_MODEL=glm-4-9b
LLM_BINDING_HOST=http://10.8.0.8:8000/v1
LLM_BINDING_API_KEY=not-needed
LLM_TIMEOUT=300

### OpenAI Compatible Specific Parameters
### Tăng temperature để tránh infinite loop với Qwen3
# OPENAI_LLM_TEMPERATURE=0.7
### Set max_tokens để tránh endless output
OPENAI_LLM_MAX_TOKENS=9000
### Tắt Reasoning/Thinking để tăng tốc độ phản hồi
### ⚠️ Model GLM-4.7-Flash có reasoning mode làm chậm ~2-3s mỗi request
OPENAI_LLM_EXTRA_BODY='{"chat_template_kwargs": {"enable_thinking": false}}'

#######################################################################################
### Embedding Configuration
#######################################################################################
### ⚠️ QUAN TRỌNG: LightRAG Server không hỗ trợ trực tiếp HuggingFace models
### Các lựa chọn cho Vietnamese Embedding:
###
### LỰA CHỌN 1: Sử dụng Ollama (Khuyến nghị)
### - Cài đặt Ollama và pull model embedding
### - ollama pull bge-m3 (hoặc model embedding tiếng Việt khác)
### - Thay đổi cấu hình bên dưới thành:
###
### EMBEDDING_BINDING=ollama
### EMBEDDING_MODEL=bge-m3:latest
### EMBEDDING_DIM=1024
### EMBEDDING_BINDING_HOST=http://localhost:11434
###
### LỰA CHỌN 2: Sử dụng OpenAI API
### - Nếu có API key OpenAI
### - Giữ nguyên cấu hình mặc định hoặc dùng text-embedding-3-large
###
### LỰA CHỌN 3: Tự host embedding API
### - Sử dụng text-embeddings-inference (TEI) hoặc vLLM
### - Tạo endpoint OpenAI-compatible cho model Vietnamese embedding
### - Cấu hình EMBEDDING_BINDING_HOST trỏ đến endpoint này
###
### LƯU Ý: Không thể đổi embedding model sau khi đã insert documents!
#######################################################################################

#######################################################################################
### Cấu hình Vietnamese Embedding Service (Local)
### 
### TRƯỚC KHI CHẠY LIGHTRAG SERVER:
### 1. Khởi động Vietnamese Embedding Service:
###    python vietnamese_embedding_service.py
### 
### 2. Service sẽ chạy tại http://localhost:8001/v1
###
### 3. Sau đó khởi động LightRAG Server
#######################################################################################
EMBEDDING_BINDING=openai
EMBEDDING_MODEL=vietnamese-embedding
EMBEDDING_DIM=768
EMBEDDING_SEND_DIM=false
EMBEDDING_TOKEN_LIMIT=512
EMBEDDING_BINDING_HOST=http://localhost:8001/v1
EMBEDDING_BINDING_API_KEY=not-needed

### Cấu hình dự phòng: OpenAI (nếu có API key)
# EMBEDDING_BINDING=openai
# EMBEDDING_MODEL=text-embedding-3-large
# EMBEDDING_DIM=3072
# EMBEDDING_BINDING_HOST=https://api.openai.com/v1
# EMBEDDING_BINDING_API_KEY=your_api_key_here

### Cấu hình dự phòng: Ollama
# EMBEDDING_BINDING=ollama
# EMBEDDING_MODEL=bge-m3:latest
# EMBEDDING_DIM=1024
# EMBEDDING_BINDING_HOST=http://localhost:11434

#######################################################################################
### Authentication (Optional)
#######################################################################################
### API Key để bảo vệ API
# LIGHTRAG_API_KEY=your-secure-api-key-here
# WHITELIST_PATHS=/health,/api/*

### Account credentials cho WebUI
# AUTH_ACCOUNTS='admin:admin123'
# TOKEN_SECRET=your-secret-key-for-jwt
# TOKEN_EXPIRE_HOURS=48
